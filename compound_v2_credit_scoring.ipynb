{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNVbyx7ey/QLFeB3CvgEE2b"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"goark1AMpVgq"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.cluster import KMeans\n","from sklearn.preprocessing import StandardScaler\n","from scipy.stats import entropy\n","import json\n","import os\n","import logging\n","\n","# Set up logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","# Function to load and combine large JSON files\n","def load_data(file_paths):\n","    dfs = []\n","    transaction_types = ['deposits', 'borrows', 'repays', 'withdrawals', 'liquidations']\n","\n","    for file in file_paths:\n","        logging.info(f\"Loading {file}...\")\n","        try:\n","            with open(file, 'r') as f:\n","                data = json.load(f)\n","        except Exception as e:\n","            logging.error(f\"Failed to load {file}: {e}\")\n","            continue\n","\n","        # Process each transaction type\n","        for tx_type in transaction_types:\n","            if tx_type in data and data[tx_type]:\n","                try:\n","                    # Normalize nested fields\n","                    tx_data = pd.json_normalize(data[tx_type])\n","                    # Rename columns for consistency\n","                    tx_data = tx_data.rename(columns={\n","                        'account.id': 'wallet_address',\n","                        'asset.symbol': 'asset',\n","                        'amount': 'amount',\n","                        'timestamp': 'timestamp'\n","                    })\n","                    # Check required columns\n","                    required_cols = ['wallet_address', 'amount', 'timestamp']\n","                    if not all(col in tx_data.columns for col in required_cols):\n","                        logging.warning(f\"Missing required columns in {tx_type} from {file}\")\n","                        continue\n","                    # Add transaction type column\n","                    tx_data['transaction_type'] = tx_type[:-1]  # Remove 's' (e.g., 'deposits' -> 'deposit')\n","                    # Select relevant columns\n","                    tx_data = tx_data[['wallet_address', 'transaction_type', 'amount', 'timestamp', 'asset']]\n","                    # Convert amount to numeric\n","                    tx_data['amount'] = pd.to_numeric(tx_data['amount'], errors='coerce')\n","                    dfs.append(tx_data)\n","                except Exception as e:\n","                    logging.error(f\"Error processing {tx_type} in {file}: {e}\")\n","                    continue\n","\n","    # Combine all transactions\n","    if dfs:\n","        return pd.concat(dfs, ignore_index=True)\n","    else:\n","        raise ValueError(\"No valid transaction data found in the provided files.\")\n","\n","# Feature engineering\n","def engineer_features(df):\n","    try:\n","        # Convert timestamp to datetime\n","        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n","\n","        # Aggregate by wallet\n","        wallet_features = df.groupby('wallet_address').agg({\n","            'amount': [\n","                ('total_deposit', lambda x: x[df['transaction_type'] == 'deposit'].sum()),\n","                ('total_borrow', lambda x: x[df['transaction_type'] == 'borrow'].sum()),\n","                ('total_repay', lambda x: x[df['transaction_type'] == 'repay'].sum()),\n","                ('total_withdraw', lambda x: x[df['transaction_type'] == 'withdraw'].sum()),\n","                ('total_liquidation', lambda x: x[df['transaction_type'] == 'liquidation'].sum())\n","            ],\n","            'transaction_type': [\n","                ('count_deposit', lambda x: (x == 'deposit').sum()),\n","                ('count_borrow', lambda x: (x == 'borrow').sum()),\n","                ('count_repay', lambda x: (x == 'repay').sum()),\n","                ('count_withdraw', lambda x: (x == 'withdraw').sum()),\n","                ('count_liquidation', lambda x: (x == 'liquidation').sum())\n","            ],\n","            'timestamp': [\n","                ('first_tx', 'min'),\n","                ('last_tx', 'max'),\n","                ('tx_count', 'count')\n","            ]\n","        })\n","\n","        # Flatten column names\n","        wallet_features.columns = [f\"{x}_{y}\" for x, y in wallet_features.columns]\n","\n","        # Calculate additional features\n","        wallet_features['borrow_to_deposit_ratio'] = (\n","            wallet_features['amount_total_borrow'] / (wallet_features['amount_total_deposit'] + 1e-6)\n","        )\n","        wallet_features['repay_to_borrow_ratio'] = (\n","            wallet_features['amount_total_repay'] / (wallet_features['amount_total_borrow'] + 1e-6)\n","        )\n","        wallet_features['liquidation_to_borrow_ratio'] = (\n","            wallet_features['amount_total_liquidation'] / (wallet_features['amount_total_borrow'] + 1e-6)\n","        )\n","        wallet_features['activity_span_days'] = (\n","            (wallet_features['timestamp_last_tx'] - wallet_features['timestamp_first_tx']).dt.days\n","        )\n","        wallet_features['avg_tx_per_day'] = (\n","            wallet_features['timestamp_tx_count'] / (wallet_features['activity_span_days'] + 1)\n","        )\n","\n","        # Transaction pattern entropy\n","        def calculate_entropy(wallet_df):\n","            times = wallet_df['timestamp'].sort_values()\n","            intervals = times.diff().dt.total_seconds().dropna()\n","            if len(intervals) < 2:\n","                return 0\n","            hist, _ = np.histogram(intervals, bins=10, density=True)\n","            return entropy(hist + 1e-6)\n","\n","        entropy_features = df.groupby('wallet_address').apply(calculate_entropy).rename('tx_entropy')\n","        wallet_features = wallet_features.join(entropy_features)\n","\n","        # Handle infinities and NaNs\n","        wallet_features = wallet_features.replace([np.inf, -np.inf], 0).fillna(0)\n","\n","        return wallet_features\n","    except Exception as e:\n","        logging.error(f\"Error in feature engineering: {e}\")\n","        raise\n","\n","# Scoring model\n","def compute_scores(features):\n","    try:\n","        # Select relevant features for clustering\n","        feature_cols = [\n","            'amount_total_deposit', 'amount_total_borrow', 'amount_total_repay',\n","            'amount_total_withdraw', 'amount_total_liquidation',\n","            'borrow_to_deposit_ratio', 'repay_to_borrow_ratio',\n","            'liquidation_to_borrow_ratio', 'count_deposit', 'count_borrow',\n","            'count_repay', 'count_withdraw', 'count_liquidation',\n","            'activity_span_days', 'avg_tx_per_day', 'tx_entropy'\n","        ]\n","\n","        X = features[feature_cols].values\n","        scaler = StandardScaler()\n","        X_scaled = scaler.fit_transform(X)\n","\n","        # K-means clustering\n","        kmeans = KMeans(n_clusters=5, random_state=42)\n","        features['cluster'] = kmeans.fit_predict(X_scaled)\n","\n","        # Score based on cluster characteristics\n","        cluster_scores = []\n","        for cluster in range(5):\n","            cluster_data = features[features['cluster'] == cluster]\n","            score = (\n","                0.3 * cluster_data['repay_to_borrow_ratio'].mean() -\n","                0.3 * cluster_data['liquidation_to_borrow_ratio'].mean() +\n","                0.2 * cluster_data['amount_total_deposit'].mean() /\n","                (cluster_data['amount_total_borrow'].mean() + 1e-6) +\n","                0.1 * cluster_data['activity_span_days'].mean() /\n","                (cluster_data['avg_tx_per_day'].mean() + 1e-6) -\n","                0.1 * cluster_data['tx_entropy'].mean()\n","            )\n","            cluster_scores.append(score)\n","\n","        # Normalize scores to 0â€“100\n","        cluster_scores = np.array(cluster_scores)\n","        normalized_scores = 100 * (cluster_scores - cluster_scores.min()) / (cluster_scores.max() - cluster_scores.min() + 1e-6)\n","        features['score'] = features['cluster'].map(dict(enumerate(normalized_scores)))\n","\n","        return features[['score']]\n","    except Exception as e:\n","        logging.error(f\"Error in scoring: {e}\")\n","        raise\n","\n","# Main execution\n","if __name__ == \"__main__\":\n","    # Placeholder for file paths (replace with actual paths from Google Drive)\n","    file_paths = [\n","        \"/content/compoundV2_transactions_ethereum_chunk_0.json\",\n","        \"/content/compoundV2_transactions_ethereum_chunk_4.json\",\n","        \"/content/compoundV2_transactions_ethereum_chunk_7.json\"\n","    ]\n","\n","    try:\n","        # Load data\n","        df = load_data(file_paths)\n","\n","        # Engineer features\n","        features = engineer_features(df)\n","\n","        # Compute scores\n","        scores = compute_scores(features)\n","\n","        # Output top 1,000 wallets\n","        top_wallets = scores.sort_values('score', ascending=False).head(1000)\n","        top_wallets.to_csv('wallet_scores.csv')\n","\n","        logging.info(\"Scoring complete. Output saved to wallet_scores.csv\")\n","    except Exception as e:\n","        logging.error(f\"Main execution failed: {e}\")"]}]}